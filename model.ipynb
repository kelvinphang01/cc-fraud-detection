{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b8b391",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b7e19f",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abbf2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "import multiprocessing as mp\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from utils import clean_data, KFold, predict, feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e5780",
   "metadata": {},
   "source": [
    "Load and process train data\n",
    "\n",
    "Data preprocessing (feature engineering, selection) and data cleaning from `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e693a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data from Kaggle dataset [Credit Card Transactions Fraud Detection Dataset]\n",
    "# Dataset created by KARTIK SHENOY and available under CC0\n",
    "df_train = pd.read_csv('data/fraudTrain.csv')\n",
    "\n",
    "# Clean train data\n",
    "X, y = clean_data(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d006e5",
   "metadata": {},
   "source": [
    "Train Random Forest model with different class weights with K-Fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2ed6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Class weights: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1289169\n",
      "           1       0.90      0.68      0.77      7506\n",
      "\n",
      "    accuracy                           1.00   1296675\n",
      "   macro avg       0.95      0.84      0.89   1296675\n",
      "weighted avg       1.00      1.00      1.00   1296675\n",
      "\n",
      "==============================\n",
      "Class weights: {0: 1, 1: 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1289169\n",
      "           1       0.78      0.75      0.77      7506\n",
      "\n",
      "    accuracy                           1.00   1296675\n",
      "   macro avg       0.89      0.88      0.88   1296675\n",
      "weighted avg       1.00      1.00      1.00   1296675\n",
      "\n",
      "==============================\n",
      "Class weights: {0: 1, 1: 75}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1289169\n",
      "           1       0.75      0.77      0.76      7506\n",
      "\n",
      "    accuracy                           1.00   1296675\n",
      "   macro avg       0.87      0.88      0.88   1296675\n",
      "weighted avg       1.00      1.00      1.00   1296675\n",
      "\n",
      "==============================\n",
      "Class weights: {0: 1, 1: 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1289169\n",
      "           1       0.70      0.78      0.74      7506\n",
      "\n",
      "    accuracy                           1.00   1296675\n",
      "   macro avg       0.85      0.89      0.87   1296675\n",
      "weighted avg       1.00      1.00      1.00   1296675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Random Forest\n",
    "# RFC list for different class weights\n",
    "rf_classifiers = []\n",
    "rfc_class_weights = [None, {0: 1, 1: 50}, {0: 1, 1: 75}, {0: 1, 1: 100}]\n",
    "\n",
    "# Define model with parameters\n",
    "for cw in rfc_class_weights:\n",
    "    rf_params = {\n",
    "        'n_estimators': 50,\n",
    "        'max_depth': 20,\n",
    "        'class_weight': cw,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': mp.cpu_count()\n",
    "        }\n",
    "    \n",
    "    rf_classifier = RFC(**rf_params)\n",
    "    rf_classifiers.append(rf_classifier)\n",
    "    KFold(rf_classifier, cw, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c127b8",
   "metadata": {},
   "source": [
    "The same for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40a4c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Class weights: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1289169\n",
      "           1       0.89      0.70      0.78      7506\n",
      "\n",
      "    accuracy                           1.00   1296675\n",
      "   macro avg       0.94      0.85      0.89   1296675\n",
      "weighted avg       1.00      1.00      1.00   1296675\n",
      "\n",
      "==============================\n",
      "Class weights: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1289169\n",
      "           1       0.82      0.76      0.79      7506\n",
      "\n",
      "    accuracy                           1.00   1296675\n",
      "   macro avg       0.91      0.88      0.89   1296675\n",
      "weighted avg       1.00      1.00      1.00   1296675\n",
      "\n",
      "==============================\n",
      "Class weights: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1289169\n",
      "           1       0.79      0.78      0.79      7506\n",
      "\n",
      "    accuracy                           1.00   1296675\n",
      "   macro avg       0.90      0.89      0.89   1296675\n",
      "weighted avg       1.00      1.00      1.00   1296675\n",
      "\n",
      "==============================\n",
      "Class weights: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1289169\n",
      "           1       0.76      0.79      0.77      7506\n",
      "\n",
      "    accuracy                           1.00   1296675\n",
      "   macro avg       0.88      0.89      0.89   1296675\n",
      "weighted avg       1.00      1.00      1.00   1296675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## XGBoost\n",
    "# XGBC list for different class weights\n",
    "xgb_classifiers = []\n",
    "xgbc_class_weights = [None, 10, 20, 30]\n",
    "\n",
    "# Define model with parameters\n",
    "for cw in xgbc_class_weights:\n",
    "    xgb_params = {\n",
    "        'max_depth': 20,\n",
    "        'n_estimators': 50,\n",
    "        'learning_rate': 0.1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'scale_pos_weight': cw,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "        }\n",
    "    \n",
    "    xgb_classifier = XGBC(**xgb_params)\n",
    "    xgb_classifiers.append(xgb_classifier)\n",
    "    KFold(xgb_classifier, cw, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6c69a9",
   "metadata": {},
   "source": [
    "All models look good and will be used for deployment. (Stored in lists)\n",
    "\n",
    "Savings and number of false detections will be evaluated in the deployment stage for further insights on the different class weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af7957",
   "metadata": {},
   "source": [
    "## Deployment on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e1a7e",
   "metadata": {},
   "source": [
    "Load and process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6deaf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data from Kaggle dataset [Credit Card Transactions Fraud Detection Dataset]\n",
    "# Dataset created by KARTIK SHENOY and available under CC0\n",
    "df_test = pd.read_csv('data/fraudTest.csv')\n",
    "\n",
    "# Clean test data\n",
    "X_test, y_test = clean_data(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a085d6",
   "metadata": {},
   "source": [
    "Make predictions with Random Forest models and XGBoost models respectively.\n",
    "\n",
    "Savings are calculated through *total detected fraud amount* - *total cost of false detections*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96064a5d",
   "metadata": {},
   "source": [
    "Random Forest models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ad36d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Class weight: None\n",
      "Recall: 0.6615384615384615\n",
      "Precision: 0.8636640292148509\n",
      "F1 score: 0.749208025343189\n",
      "AUPRC: 0.7783081993842402\n",
      "Total Fraud Amount: 1133324.6800000002\n",
      "Total Detected Fraud Amount: 880840.3699999999\n",
      "Total Cost of Detection: 63253.6500875\n",
      "Total Savings: 817586.7199124999\n",
      "Total False Detections: 224\n",
      "\n",
      "==============================\n",
      "Class weight: {0: 1, 1: 50}\n",
      "Recall: 0.7417249417249417\n",
      "Precision: 0.7002640845070423\n",
      "F1 score: 0.7203984604935475\n",
      "AUPRC: 0.7775362428406877\n",
      "Total Fraud Amount: 1133324.6800000002\n",
      "Total Detected Fraud Amount: 998703.8999999999\n",
      "Total Cost of Detection: 89207.0352875\n",
      "Total Savings: 909496.8647124999\n",
      "Total False Detections: 681\n",
      "\n",
      "==============================\n",
      "Class weight: {0: 1, 1: 75}\n",
      "Recall: 0.7659673659673659\n",
      "Precision: 0.6319230769230769\n",
      "F1 score: 0.6925184404636459\n",
      "AUPRC: 0.7670501989479446\n",
      "Total Fraud Amount: 1133324.6800000002\n",
      "Total Detected Fraud Amount: 1026367.81\n",
      "Total Cost of Detection: 102464.52495\n",
      "Total Savings: 923903.2850500001\n",
      "Total False Detections: 957\n",
      "\n",
      "==============================\n",
      "Class weight: {0: 1, 1: 100}\n",
      "Recall: 0.7874125874125875\n",
      "Precision: 0.575076608784474\n",
      "F1 score: 0.6646989374262102\n",
      "AUPRC: 0.7623635707984711\n",
      "Total Fraud Amount: 1133324.6800000002\n",
      "Total Detected Fraud Amount: 1041013.01\n",
      "Total Cost of Detection: 115658.1781\n",
      "Total Savings: 925354.8319\n",
      "Total False Detections: 1248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict with Random Forest\n",
    "rfc_best = None\n",
    "for idx, rfc in enumerate(rf_classifiers):\n",
    "    \n",
    "    # Fit the model\n",
    "    rfc.fit(X, y)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    \n",
    "    # Predict and best RFC\n",
    "    if not rfc_best:\n",
    "        rfc_best = rfc\n",
    "        savings_best = predict(y_pred, rfc_class_weights, rfc, X_test, y_test, idx)\n",
    "    else:\n",
    "        total_savings = predict(y_pred, rfc_class_weights, rfc, X_test, y_test, idx)\n",
    "        if total_savings > savings_best:\n",
    "            rfc_best = rfc\n",
    "            savings_best = total_savings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df1d583",
   "metadata": {},
   "source": [
    "Feature importance of best Random Forest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db972abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Feature  Importance\n",
      "0                           amt    0.629406\n",
      "4   time_since_prev_transaction    0.101995\n",
      "3              is_working_hours    0.057340\n",
      "1                      city_pop    0.024766\n",
      "10       category_gas_transport    0.022753\n",
      "7                      distance    0.021952\n",
      "19        category_shopping_net    0.019917\n",
      "12         category_grocery_pos    0.017760\n",
      "2                         is_AM    0.016639\n",
      "14                category_home    0.009529\n",
      "16            category_misc_net    0.009429\n",
      "20        category_shopping_pos    0.009119\n",
      "9          category_food_dining    0.009084\n",
      "21              category_travel    0.007200\n",
      "17            category_misc_pos    0.006561\n",
      "5               day_of_week_sin    0.006415\n",
      "8        category_entertainment    0.005760\n",
      "6               day_of_week_cos    0.005639\n",
      "15           category_kids_pets    0.005473\n",
      "11         category_grocery_net    0.005131\n",
      "13      category_health_fitness    0.004458\n",
      "18       category_personal_care    0.003674\n"
     ]
    }
   ],
   "source": [
    "feature_importance(rfc_best, X) # Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79227cf3",
   "metadata": {},
   "source": [
    "XGBoost models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6d949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Class weight: None\n",
      "Recall: 0.654079254079254\n",
      "Precision: 0.8735990037359901\n",
      "F1 score: 0.7480671820847774\n",
      "AUPRC: 0.8076745423514735\n",
      "Total Fraud Amount: 1133324.6800000002\n",
      "Total Detected Fraud Amount: 857378.67\n",
      "Total Cost of Detection: 61674.666925\n",
      "Total Savings: 795704.003075\n",
      "Total False Detections: 203\n",
      "\n",
      "==============================\n",
      "Class weight: 10\n",
      "Recall: 0.7314685314685314\n",
      "Precision: 0.7642474427666829\n",
      "F1 score: 0.7474988089566459\n",
      "AUPRC: 0.8035576984161339\n",
      "Total Fraud Amount: 1133324.6800000002\n",
      "Total Detected Fraud Amount: 978850.18\n",
      "Total Cost of Detection: 79980.0518875\n",
      "Total Savings: 898870.1281125001\n",
      "Total False Detections: 484\n",
      "\n",
      "==============================\n",
      "Class weight: 20\n",
      "Recall: 0.7482517482517482\n",
      "Precision: 0.7322080291970803\n",
      "F1 score: 0.7401429559603412\n",
      "AUPRC: 0.7998477858040268\n",
      "Total Fraud Amount: 1133324.6800000002\n",
      "Total Detected Fraud Amount: 995242.23\n",
      "Total Cost of Detection: 85500.8609375\n",
      "Total Savings: 909741.3690625\n",
      "Total False Detections: 587\n",
      "\n",
      "==============================\n",
      "Class weight: 30\n",
      "Recall: 0.7659673659673659\n",
      "Precision: 0.6961864406779661\n",
      "F1 score: 0.7294117647058823\n",
      "AUPRC: 0.8006888921807145\n",
      "Total Fraud Amount: 1133324.6800000002\n",
      "Total Detected Fraud Amount: 1019386.12\n",
      "Total Cost of Detection: 92201.37565\n",
      "Total Savings: 927184.74435\n",
      "Total False Detections: 717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict with XGBoost\n",
    "xgbc_best = None\n",
    "for idx, xgbc in enumerate(xgb_classifiers):\n",
    "    \n",
    "    # Fit the model\n",
    "    xgbc.fit(X, y)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = xgbc.predict(X_test)\n",
    "    \n",
    "    # Predict and best RFC\n",
    "    if not xgbc_best:\n",
    "        xgbc_best = xgbc\n",
    "        savings_best = predict(y_pred, xgbc_class_weights, xgbc, X_test, y_test, idx)\n",
    "    else:\n",
    "        total_savings = predict(y_pred, xgbc_class_weights, xgbc, X_test, y_test, idx)\n",
    "        if total_savings > savings_best:\n",
    "            xgbc_best = xgbc\n",
    "            savings_best = total_savings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47e21b",
   "metadata": {},
   "source": [
    "Feature importance of best XGBoost model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48853084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Feature  Importance\n",
      "10       category_gas_transport    0.356184\n",
      "12         category_grocery_pos    0.089642\n",
      "11         category_grocery_net    0.080958\n",
      "21              category_travel    0.072154\n",
      "3              is_working_hours    0.064494\n",
      "0                           amt    0.056835\n",
      "14                category_home    0.054262\n",
      "8        category_entertainment    0.039145\n",
      "9          category_food_dining    0.025886\n",
      "17            category_misc_pos    0.025070\n",
      "19        category_shopping_net    0.022345\n",
      "13      category_health_fitness    0.021984\n",
      "2                         is_AM    0.018143\n",
      "15           category_kids_pets    0.016955\n",
      "18       category_personal_care    0.016239\n",
      "20        category_shopping_pos    0.011562\n",
      "16            category_misc_net    0.010004\n",
      "4   time_since_prev_transaction    0.005685\n",
      "1                      city_pop    0.003611\n",
      "5               day_of_week_sin    0.003191\n",
      "6               day_of_week_cos    0.003005\n",
      "7                      distance    0.002646\n"
     ]
    }
   ],
   "source": [
    "feature_importance(xgbc_best, X) # Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b9d70",
   "metadata": {},
   "source": [
    "Feature importance from both models show two different training patterns.\n",
    "\n",
    "Therefore, both models are combined into an ensemble learning model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "688a08df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Recall: 0.7701631701631702\n",
      "Precision: 0.6789971228935471\n",
      "F1 score: 0.7217125382262998\n",
      "AUPRC: 0.7935791579496215\n",
      "Total Fraud Amount: 1133324.6800000002\n",
      "Total Detected Fraud Amount: 1031386.13\n",
      "Total Cost of Detection: 95310.8618625\n",
      "Total Savings: 936075.2681375\n",
      "Total False Detections: 781\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "936075.2681375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a VotingClassifier with the cross-validated predictions as inputs\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('random_forest', rfc_best), ('xgboost', xgbc_best)],\n",
    "    voting='soft',\n",
    "    weights=[1, 1]\n",
    ")\n",
    "\n",
    "# Train the VotingClassifier on the entire training dataset\n",
    "voting_classifier.fit(X, y)\n",
    "\n",
    "# Ensemble model\n",
    "ensemble_preds = voting_classifier.predict(X_test)\n",
    "predict(ensemble_preds, None, voting_classifier, X_test, y_test, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ee955",
   "metadata": {},
   "source": [
    "The total savings achieved is higher than the best models from Random Forest and XGBoost.\n",
    "\n",
    "Although the number of false detections is slightly higher than the best model from XGBoost, it is significantly lower than the best model from Random Forest.\n",
    "\n",
    "Hence, this will be the final best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
